@article{LIU2025104099,
title = {Towards realistic evaluation of cultural value alignment in large language models: Diversity enhancement for survey response simulation},
journal = {Information Processing & Management},
volume = {62},
number = {4},
pages = {104099},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104099},
url = {https://www.sciencedirect.com/science/article/pii/S030645732500041X},
author = {Haijiang Liu and Yong Cao and Xun Wu and Chen Qiu and Jinguang Gu and Maofu Liu and Daniel Hershcovich},
keywords = {Evaluation methods, Value investigation, Survey simulation, Large language models, U.S.-china cultures},
abstract = {Assessing Large Language Models (LLMs) alignment with human values has been a high priority in natural language processing. These models, praised as reservoirs of collective human knowledge, provoke an important question: Do they genuinely reflect the value preferences embraced by different cultures? We measure value alignment by simulating sociological surveys and comparing the distribution of preferences from model responses to human references. We introduce a diversity-enhancement framework featuring a novel memory simulation mechanism, which enables the generation of model preference distributions and captures the diversity and uncertainty inherent in LLM behaviors through realistic survey experiments. To better understand the causes of misalignment, we have developed comprehensive evaluation metrics. Our analysis of multilingual survey data illustrates that our framework improves the reliability of cultural value alignment assessments and captures the complexity of model responses across cultural contexts. Among the eleven models evaluated, the Mistral and Llama-3 series show superior alignment with cultural values, with Mistral-series models notably excelling in comprehending these values in both U.S. and Chinese contexts.11https://github.com/alexc-l/DEF-Survey-Sim.}
}