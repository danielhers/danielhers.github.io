@inproceedings{aralikatte-etal-2019-rewarding,
    title = "Rewarding Coreference Resolvers for Being Consistent with World Knowledge",
    author = "Aralikatte, Rahul  and
      Lent, Heather  and
      Gonzalez, Ana Valeria  and
      Hershcovich, Daniel  and
      Qiu, Chen  and
      Sandholm, Anders  and
      Ringaard, Michael  and
      S{\o}gaard, Anders",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1118",
    doi = "10.18653/v1/D19-1118",
    pages = "1229--1235",
    abstract = "Unresolved coreference is a bottleneck for relation extraction, and high-quality coreference resolvers may produce an output that makes it a lot easier to extract knowledge triples. We show how to improve coreference resolvers by forwarding their input to a relation extraction system and reward the resolvers for producing triples that are found in knowledge bases. Since relation extraction systems can rely on different forms of supervision and be biased in different ways, we obtain the best performance, improving over the state of the art, using multi-task reinforcement learning.",
}

