@inproceedings{cao-etal-2023-pay,
    title = "Pay More Attention to Relation Exploration for Knowledge Base Question Answering",
    author = "Cao, Yong  and
      Li, Xianzhi  and
      Liu, Huiwen  and
      Dai, Wen  and
      Chen, Shuai  and
      Wang, Bin  and
      Chen, Min  and
      Hershcovich, Daniel",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.133",
    pages = "2119--2136",
    abstract = "Knowledge base question answering (KBQA) is a challenging task that aims to retrieve correct answers from large-scale knowledge bases. Existing attempts primarily focus on entity representation and final answer reasoning, which results in limited supervision for this task. Moreover, the relations, which empirically determine the reasoning path selection, are not fully considered in recent advancements. In this study, we propose a novel framework, RE-KBQA, that utilizes relations in the knowledge base to enhance entity representation and introduce additional supervision. We explore guidance from relations in three aspects, including (1) distinguishing similar entities by employing a variational graph auto-encoder to learn relation importance; (2) exploring extra supervision by predicting relation distributions as soft labels with a multi-task scheme; (3) designing a relation-guided re-ranking algorithm for post-processing. Experimental results on two benchmark datasets demonstrate the effectiveness and superiority of our framework, improving the F1 score by 5.8{\%} from 40.5 to 46.3 on CWQ and 5.7{\%} from 62.8 to 68.5 on WebQSP, better or on par with state-of-the-art methods.",
}
